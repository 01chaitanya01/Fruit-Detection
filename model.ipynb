{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading plants-type-datasets, 982641259 bytes compressed\n",
      "[==================================================] 982641259 bytes downloaded\n",
      "Downloaded and uncompressed: plants-type-datasets\n",
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import unquote, urlparse\n",
    "from urllib.error import HTTPError\n",
    "from zipfile import ZipFile\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "CHUNK_SIZE = 40960\n",
    "DATA_SOURCE_MAPPING = 'plants-type-datasets:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1047938%2F7170186%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240212%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240212T134003Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D30a55eb137e406488ce26901207adafb1f252cfff10bc27c093f96d0617fdfc0e72157609f3f10674a26610f3928c1c90905027d3736d42a52c40673e8df5ee577c2b979ebadc3494b74c22e6d161517be2955f2d6c3ec030c54ee0bcc27d5ccbf37902be9d6f196bfdd734c6d2ca0e0b8d8d8adf61d23f05f6a9ea7c3295fed01862d3b8281552bbe0f6303277a4341293d9b6900d8d7aace2392c2ee00c5d1ad48633c4381ce237e116405a41c639ab674808591d486a2ee02e6abd90b9734e4ab81e5e67cd83d124baf6f14f4bdaa49979c4a30d2a10f6425dcaa0fc3db9b5bf833e8459c3ab3dbb28744ea611e0ec2d9e8ce9fc68456a3b3dd67c4574f2c'\n",
    "\n",
    "KAGGLE_INPUT_PATH='/kaggle/input'\n",
    "KAGGLE_WORKING_PATH='/kaggle/working'\n",
    "KAGGLE_SYMLINK='kaggle'\n",
    "\n",
    "!umount /kaggle/input/ 2> /dev/null\n",
    "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
    "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
    "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
    "\n",
    "try:\n",
    "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "try:\n",
    "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
    "    directory, download_url_encoded = data_source_mapping.split(':')\n",
    "    download_url = unquote(download_url_encoded)\n",
    "    filename = urlparse(download_url).path\n",
    "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
    "    try:\n",
    "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
    "            total_length = fileres.headers['content-length']\n",
    "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
    "            dl = 0\n",
    "            data = fileres.read(CHUNK_SIZE)\n",
    "            while len(data) > 0:\n",
    "                dl += len(data)\n",
    "                tfile.write(data)\n",
    "                done = int(50 * dl / int(total_length))\n",
    "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
    "                sys.stdout.flush()\n",
    "                data = fileres.read(CHUNK_SIZE)\n",
    "            if filename.endswith('.zip'):\n",
    "              with ZipFile(tfile) as zfile:\n",
    "                zfile.extractall(destination_path)\n",
    "            else:\n",
    "              with tarfile.open(tfile.name) as tarfile:\n",
    "                tarfile.extractall(destination_path)\n",
    "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
    "    except HTTPError as e:\n",
    "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
    "        continue\n",
    "    except OSError as e:\n",
    "        print(f'Failed to load {download_url} to path {destination_path}')\n",
    "        continue\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Found 23972 images belonging to 30 classes.\n",
      "Found 2998 images belonging to 30 classes.\n",
      "Found 3030 images belonging to 30 classes.\n",
      "Epoch 1/50\n",
      "749/749 [==============================] - 330s 439ms/step - loss: 2.3787 - accuracy: 0.2678 - val_loss: 1.7392 - val_accuracy: 0.4382\n",
      "Epoch 2/50\n",
      "749/749 [==============================] - 318s 425ms/step - loss: 1.7779 - accuracy: 0.4387 - val_loss: 1.4852 - val_accuracy: 0.5166\n",
      "Epoch 3/50\n",
      "749/749 [==============================] - 214s 285ms/step - loss: 1.5118 - accuracy: 0.5143 - val_loss: 1.2440 - val_accuracy: 0.5894\n",
      "Epoch 4/50\n",
      "749/749 [==============================] - 158s 210ms/step - loss: 1.3420 - accuracy: 0.5660 - val_loss: 1.1233 - val_accuracy: 0.6300\n",
      "Epoch 5/50\n",
      "749/749 [==============================] - 164s 218ms/step - loss: 1.1969 - accuracy: 0.6112 - val_loss: 1.2038 - val_accuracy: 0.6054\n",
      "Epoch 6/50\n",
      "749/749 [==============================] - 159s 213ms/step - loss: 1.1138 - accuracy: 0.6363 - val_loss: 0.8302 - val_accuracy: 0.7178\n",
      "Epoch 7/50\n",
      "749/749 [==============================] - 165s 220ms/step - loss: 1.0223 - accuracy: 0.6625 - val_loss: 0.8151 - val_accuracy: 0.7224\n",
      "Epoch 8/50\n",
      "749/749 [==============================] - 157s 209ms/step - loss: 0.9500 - accuracy: 0.6892 - val_loss: 0.7826 - val_accuracy: 0.7400\n",
      "Epoch 9/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.8867 - accuracy: 0.7038 - val_loss: 0.8134 - val_accuracy: 0.7247\n",
      "Epoch 10/50\n",
      "749/749 [==============================] - 162s 216ms/step - loss: 0.8403 - accuracy: 0.7214 - val_loss: 0.6284 - val_accuracy: 0.7812\n",
      "Epoch 11/50\n",
      "749/749 [==============================] - 161s 215ms/step - loss: 0.7832 - accuracy: 0.7404 - val_loss: 0.5741 - val_accuracy: 0.8005\n",
      "Epoch 12/50\n",
      "749/749 [==============================] - 165s 220ms/step - loss: 0.7581 - accuracy: 0.7491 - val_loss: 0.5998 - val_accuracy: 0.8032\n",
      "Epoch 13/50\n",
      "749/749 [==============================] - 157s 210ms/step - loss: 0.7146 - accuracy: 0.7609 - val_loss: 0.5720 - val_accuracy: 0.8108\n",
      "Epoch 14/50\n",
      "749/749 [==============================] - 164s 218ms/step - loss: 0.6948 - accuracy: 0.7651 - val_loss: 0.4885 - val_accuracy: 0.8245\n",
      "Epoch 15/50\n",
      "749/749 [==============================] - 156s 209ms/step - loss: 0.6540 - accuracy: 0.7806 - val_loss: 0.4839 - val_accuracy: 0.8281\n",
      "Epoch 16/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.6422 - accuracy: 0.7845 - val_loss: 0.5132 - val_accuracy: 0.8291\n",
      "Epoch 17/50\n",
      "749/749 [==============================] - 158s 211ms/step - loss: 0.6318 - accuracy: 0.7929 - val_loss: 0.4902 - val_accuracy: 0.8331\n",
      "Epoch 18/50\n",
      "749/749 [==============================] - 157s 210ms/step - loss: 0.6061 - accuracy: 0.7993 - val_loss: 0.6781 - val_accuracy: 0.7896\n",
      "Epoch 19/50\n",
      "749/749 [==============================] - 158s 211ms/step - loss: 0.5853 - accuracy: 0.8070 - val_loss: 0.4693 - val_accuracy: 0.8507\n",
      "Epoch 20/50\n",
      "749/749 [==============================] - 158s 211ms/step - loss: 0.5460 - accuracy: 0.8180 - val_loss: 0.3819 - val_accuracy: 0.8750\n",
      "Epoch 21/50\n",
      "749/749 [==============================] - 162s 217ms/step - loss: 0.5529 - accuracy: 0.8207 - val_loss: 0.4243 - val_accuracy: 0.8521\n",
      "Epoch 22/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.5356 - accuracy: 0.8237 - val_loss: 0.3972 - val_accuracy: 0.8763\n",
      "Epoch 23/50\n",
      "749/749 [==============================] - 161s 215ms/step - loss: 0.5181 - accuracy: 0.8295 - val_loss: 0.3533 - val_accuracy: 0.8800\n",
      "Epoch 24/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.5216 - accuracy: 0.8308 - val_loss: 0.3839 - val_accuracy: 0.8733\n",
      "Epoch 25/50\n",
      "749/749 [==============================] - 159s 213ms/step - loss: 0.4901 - accuracy: 0.8372 - val_loss: 0.3411 - val_accuracy: 0.8846\n",
      "Epoch 26/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.4793 - accuracy: 0.8443 - val_loss: 0.4576 - val_accuracy: 0.8511\n",
      "Epoch 27/50\n",
      "749/749 [==============================] - 156s 209ms/step - loss: 0.4808 - accuracy: 0.8424 - val_loss: 0.3905 - val_accuracy: 0.8690\n",
      "Epoch 28/50\n",
      "749/749 [==============================] - 161s 215ms/step - loss: 0.4869 - accuracy: 0.8416 - val_loss: 0.2887 - val_accuracy: 0.9009\n",
      "Epoch 29/50\n",
      "749/749 [==============================] - 156s 207ms/step - loss: 0.4634 - accuracy: 0.8486 - val_loss: 0.2940 - val_accuracy: 0.9013\n",
      "Epoch 30/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.4444 - accuracy: 0.8553 - val_loss: 0.2942 - val_accuracy: 0.9053\n",
      "Epoch 31/50\n",
      "749/749 [==============================] - 156s 209ms/step - loss: 0.4565 - accuracy: 0.8525 - val_loss: 0.2947 - val_accuracy: 0.9069\n",
      "Epoch 32/50\n",
      "749/749 [==============================] - 158s 211ms/step - loss: 0.4476 - accuracy: 0.8575 - val_loss: 0.2628 - val_accuracy: 0.9069\n",
      "Epoch 33/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.4248 - accuracy: 0.8609 - val_loss: 0.2498 - val_accuracy: 0.9189\n",
      "Epoch 34/50\n",
      "749/749 [==============================] - 166s 222ms/step - loss: 0.4182 - accuracy: 0.8626 - val_loss: 0.3002 - val_accuracy: 0.9009\n",
      "Epoch 35/50\n",
      "749/749 [==============================] - 178s 237ms/step - loss: 0.4282 - accuracy: 0.8636 - val_loss: 0.3704 - val_accuracy: 0.8866\n",
      "Epoch 36/50\n",
      "749/749 [==============================] - 168s 224ms/step - loss: 0.4020 - accuracy: 0.8675 - val_loss: 0.2872 - val_accuracy: 0.9043\n",
      "Epoch 37/50\n",
      "749/749 [==============================] - 168s 224ms/step - loss: 0.4064 - accuracy: 0.8649 - val_loss: 0.3323 - val_accuracy: 0.8959\n",
      "Epoch 38/50\n",
      "749/749 [==============================] - 160s 213ms/step - loss: 0.4031 - accuracy: 0.8713 - val_loss: 0.3929 - val_accuracy: 0.8890\n",
      "Epoch 39/50\n",
      "749/749 [==============================] - 170s 226ms/step - loss: 0.4035 - accuracy: 0.8689 - val_loss: 0.2110 - val_accuracy: 0.9312\n",
      "Epoch 40/50\n",
      "749/749 [==============================] - 167s 222ms/step - loss: 0.3829 - accuracy: 0.8780 - val_loss: 0.4284 - val_accuracy: 0.8783\n",
      "Epoch 41/50\n",
      "749/749 [==============================] - 164s 218ms/step - loss: 0.3922 - accuracy: 0.8757 - val_loss: 0.3224 - val_accuracy: 0.8936\n",
      "Epoch 42/50\n",
      "749/749 [==============================] - 165s 220ms/step - loss: 0.3904 - accuracy: 0.8758 - val_loss: 0.2460 - val_accuracy: 0.9265\n",
      "Epoch 43/50\n",
      "749/749 [==============================] - 157s 210ms/step - loss: 0.3818 - accuracy: 0.8794 - val_loss: 0.2728 - val_accuracy: 0.9219\n",
      "Epoch 44/50\n",
      "749/749 [==============================] - 159s 212ms/step - loss: 0.3832 - accuracy: 0.8771 - val_loss: 0.2447 - val_accuracy: 0.9272\n",
      "Epoch 45/50\n",
      "749/749 [==============================] - 158s 210ms/step - loss: 0.3665 - accuracy: 0.8807 - val_loss: 0.2668 - val_accuracy: 0.9156\n",
      "Epoch 46/50\n",
      "749/749 [==============================] - 160s 214ms/step - loss: 0.3786 - accuracy: 0.8778 - val_loss: 0.2209 - val_accuracy: 0.9322\n",
      "Epoch 47/50\n",
      "749/749 [==============================] - 157s 209ms/step - loss: 0.3485 - accuracy: 0.8885 - val_loss: 0.3407 - val_accuracy: 0.8973\n",
      "Epoch 48/50\n",
      "749/749 [==============================] - 157s 210ms/step - loss: 0.3829 - accuracy: 0.8774 - val_loss: 0.2994 - val_accuracy: 0.9146\n",
      "Epoch 49/50\n",
      "749/749 [==============================] - 161s 215ms/step - loss: 0.3681 - accuracy: 0.8829 - val_loss: 0.2555 - val_accuracy: 0.9132\n",
      "Epoch 50/50\n",
      "749/749 [==============================] - 157s 210ms/step - loss: 0.3471 - accuracy: 0.8913 - val_loss: 0.3320 - val_accuracy: 0.8923\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.3475 - accuracy: 0.8968\n",
      "Test accuracy: 0.8968414068222046\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available devices\n",
    "print(\"Available devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Explicitly specify GPU\n",
    "tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data directories\n",
    "train_dir = '/kaggle/input/plants-type-datasets/split_ttv_dataset_type_of_plants/Train_Set_Folder'\n",
    "test_dir = '/kaggle/input/plants-type-datasets/split_ttv_dataset_type_of_plants/Test_Set_Folder'\n",
    "validation_dir = '/kaggle/input/plants-type-datasets/split_ttv_dataset_type_of_plants/Validation_Set_Folder'\n",
    "\n",
    "# Define image size and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Create ImageDataGenerator instances with data augmentation for training and validation data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create image generators for training, testing, and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('plant_detection_model_2.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('plant_detection_model_2.h5')\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_plant(image_path):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    class_labels = train_generator.class_indices\n",
    "    predicted_label = list(class_labels.keys())[predicted_class]\n",
    "    return predicted_label, prediction[0][predicted_class]\n",
    "\n",
    "# Example usage\n",
    "input_image_path = 'aloevera42.jpg'\n",
    "predicted_label, confidence = predict_plant(input_image_path)\n",
    "print('Predicted plant:', predicted_label)\n",
    "print('Confidence:', confidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
